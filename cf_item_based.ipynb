{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于已评分的高分电影相似度做的协同推荐\n",
    "\n",
    "导入movielen数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reading ratings file\n",
    "# Ignore the timestamp column\n",
    "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Reading users file\n",
    "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将movies.genres转为数组的格式便于后续用tfidf做单词的数字化。\n",
    "\n",
    "从\n",
    "0     Animation|Children's|Comedy\n",
    "1    Adventure|Children's|Fantasy\n",
    "2                  Comedy|Romance\n",
    "3                    Comedy|Drama\n",
    "4                          Comedy\n",
    "\n",
    "到\n",
    "0     [u'Animation', u\"Children's\", u'Comedy']\n",
    "1    [u'Adventure', u\"Children's\", u'Fantasy']\n",
    "2                      [u'Comedy', u'Romance']\n",
    "3                        [u'Comedy', u'Drama']\n",
    "4                                  [u'Comedy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Animation|Children's|Comedy\n",
       "1    Adventure|Children's|Fantasy\n",
       "2                  Comedy|Romance\n",
       "3                    Comedy|Drama\n",
       "4                          Comedy\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [u'Animation', u\"Children's\", u'Comedy']\n",
       "1    [u'Adventure', u\"Children's\", u'Fantasy']\n",
       "2                      [u'Comedy', u'Romance']\n",
       "3                        [u'Comedy', u'Drama']\n",
       "4                                  [u'Comedy']\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break up the big genre string into a string array\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "# Convert genres to string value\n",
    "movies['genres'] = movies['genres'].fillna(\"\").astype('str')\n",
    "\n",
    "movies.genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于tfidf的说明见，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 127)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(movies['genres'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于TfidfVectorizer已经将向量标准化为长度1，所以可以直接用两个向量的点积作为cosine的值来判断向量之间的相似程度；因此可以用性能更好的linear_kernel来处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.14193614, 0.09010857, 0.1056164 ],\n",
       "       [0.14193614, 1.        , 0.        , 0.        ],\n",
       "       [0.09010857, 0.        , 1.        , 0.1719888 ],\n",
       "       [0.1056164 , 0.        , 0.1719888 , 1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备索引，便于后续查找数据，\n",
    "\n",
    "titles：根据索引得到电影名称\n",
    "indices：根据电影名称得到索引\n",
    "indices_movid：根据电影id得到电影的索引（电影id与索引的对应并不完全对齐）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 1-dimensional array with movie titles\n",
    "titles = movies['title']\n",
    "indices = pd.Series(movies.index, index=movies['title'])\n",
    "\n",
    "# Another one for movie id\n",
    "# movie_id -> movie index\n",
    "indices_movid = pd.Series(movies.index, index=movies['movie_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据电影名称，返回movie标签信息最接近的20个电影并返回，简单验证推荐的功能；\n",
    "cosine_sim[10]的数组，即movie索引为10的电影，与所有索引的电影的相似度数值；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13                                         Nixon (1995)\n",
      "25                                       Othello (1995)\n",
      "26                                  Now and Then (1995)\n",
      "29    Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
      "30                               Dangerous Minds (1995)\n",
      "35                              Dead Man Walking (1995)\n",
      "39                      Cry, the Beloved Country (1995)\n",
      "42                                   Restoration (1995)\n",
      "52                                      Lamerica (1994)\n",
      "54                                       Georgia (1995)\n",
      "56                         Home for the Holidays (1995)\n",
      "61                            Mr. Holland's Opus (1995)\n",
      "66                                      Two Bits (1995)\n",
      "77                           Crossing Guard, The (1995)\n",
      "79         White Balloon, The (Badkonake Sefid ) (1995)\n",
      "81                      Antonia's Line (Antonia) (1995)\n",
      "82      Once Upon a Time... When We Were Colored (1995)\n",
      "89                   Journey of August King, The (1995)\n",
      "92                               Beautiful Girls (1996)\n",
      "95                              Hate (Haine, La) (1995)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function that get movie recommendations based on the cosine similarity score of movie genres\n",
    "def genre_recommend_by_title(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[:20]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]\n",
    "\n",
    "print(genre_recommend_by_title('Good Will Hunting (1997)').head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集以默认1：3的比例以随机的方式分为训练和验证的部分，后续用验证集来验证推荐效果。\n",
    "具体见，\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train & test dataset\n",
    "ratings_train, ratings_test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_n(l, n=3):\n",
    "    \"\"\"Get the first n results from l\n",
    "    l is like,\n",
    "    l = [(1, 1.0), (2, 1.0), (3, 0.8), (4, 0.75), (5, 0.6), (6, 0.4), (7, 1.0), (8, 1.0)]\n",
    "    \n",
    "    randomnize and return n of them if candidates more than n\n",
    "    otherwise just sort and return first n of them\n",
    "    \"\"\"\n",
    "    l = sorted(l, key=lambda x:x[1], reverse=True)\n",
    "    top = l[0][-1]\n",
    "    \n",
    "    result = []\n",
    "    for x in l:\n",
    "        if x[1] == top:\n",
    "            result.append(x)\n",
    "    \n",
    "    if len(result) >= n:\n",
    "        random.shuffle(result)\n",
    "        return result[:n]\n",
    "    \n",
    "    else:\n",
    "        return l[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_recommend_by_movid_list(movie_id_list, count=10):\n",
    "    \"\"\"\n",
    "    Input: highest rated movies id\n",
    "    Output: recommend movie id list limited by count\n",
    "    \"\"\"\n",
    "    recommend_movie_index_list = []\n",
    "    sim_scores_full = []\n",
    "    \n",
    "    # Convert from movie id list to movie index list\n",
    "    idx_list = [indices_movid[movie_id] for movie_id in movie_id_list]\n",
    "    for idx in idx_list:\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        sim_scores_full.extend(sim_scores)\n",
    "        \n",
    "    # Remove watched movies\n",
    "    for sim_score in sim_scores_full:\n",
    "        if sim_score[0] in movie_id_list:\n",
    "            sim_scores_full.remove(sim_score)\n",
    "\n",
    "    # Only return <count> results\n",
    "    recommend_movie_index_list = get_first_n(sim_scores_full, n=count)\n",
    "    recommend_movie_index_list = [x[0] for x in recommend_movie_index_list]\n",
    "    \n",
    "    #print(recommend_movie_index_list)\n",
    "    # Convert from movie index list to movie id list\n",
    "    recommend_movie_id_list = \\\n",
    "        [np.asscalar(movies[movies.index == idx].movie_id) for idx in recommend_movie_index_list]\n",
    "\n",
    "    return recommend_movie_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单验证基于用户的高评分电影的相似电影做的推荐列表结果\n",
    "考虑到实际情况，为了避免每次推荐都是同样的电影，对所有最高评分的相似的电影做了随机返回，因此每次推荐的结果都会不一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, [1586, 3759, 3776, 3628, 631, 1032, 3062, 1489, 1024, 1242])\n",
      "(2, [380, 1197, 2405, 2406, 14, 26, 27, 30, 31, 36])\n",
      "(3, [380, 1197, 2405, 2406, 368, 1304, 1378, 1379, 1259, 5])\n",
      "(4, [692, 748, 2600, 3527, 3643, 1222, 1523, 1037, 3062, 3654])\n",
      "(5, [3326, 2408, 1965, 2427, 1270, 3033, 1242, 3753, 2028, 718])\n",
      "(6, [1233, 3062, 3654, 1586, 3628, 3643, 110, 3753, 2028, 1242])\n",
      "(7, [1037, 1586, 3654, 2028, 2571, 2722, 1222, 286, 3654, 1586])\n",
      "(8, [3654, 2692, 748, 2699, 110, 2600, 172, 1242, 2427, 1037])\n",
      "(9, [3753, 1222, 3377, 2972, 1696, 527, 3628, 3654, 336, 1619])\n"
     ]
    }
   ],
   "source": [
    "def print_recomm_result_by_ratings_data(ratings, rated_movie_limit=10):\n",
    "    #for user_id in np.sort(ratings['user_id'].unique()):\n",
    "    for user_id in np.arange(1, 10):\n",
    "        highest_rate_movie_id = \\\n",
    "            ratings[(ratings.user_id == user_id) & \\\n",
    "                (ratings.rating == np.max(ratings[ratings.user_id == user_id].rating))][['movie_id']]\n",
    "        \n",
    "        highest_rate_movie_id_list = highest_rate_movie_id.movie_id.values\n",
    "        # Performance will have significant impact if not limit the number of\n",
    "        # rated movies for filtering \n",
    "        random.shuffle(highest_rate_movie_id_list)\n",
    "        highest_rate_movie_id_list = highest_rate_movie_id_list[:rated_movie_limit]\n",
    "        \n",
    "        #print('debug high rate movie len:', len(highest_rate_movie_id_list))\n",
    "        \n",
    "        recommend_list = genre_recommend_by_movid_list(highest_rate_movie_id_list)\n",
    "        print(user_id, recommend_list)\n",
    "        \n",
    "print_recomm_result_by_ratings_data(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过推荐列表的命中率验证效果，使用验证集来验证推荐结果，训练集用来生成推荐列表。\n",
    "由于movielen里除了有评价过的电影还有相应的评分，为了贴合实际，认为，\n",
    "只有命中且评分高于该用户的p80的评分（有些人习惯打高分，其他人反之），才算命中\n",
    "\n",
    "会执行很久，但可以像下列例子那样仅验证头100个user的推荐的命中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.0, 990.0)\n",
      "hit ratio percentage: 1.9191919192%\n"
     ]
    }
   ],
   "source": [
    "def hit_ratio_benchmark(ratings_train, ratings_test, rated_movie_limit=10):\n",
    "    \"\"\"\n",
    "    for each user_id\n",
    "    1. get recommend list using ratings_train rated movies\n",
    "    2. use ratings_test rated movies to validate hit ratio\n",
    "    it is considered hit when,\n",
    "    1. user rated this movie\n",
    "    2. the rate is >= this user's p80 rate in ratings_train\n",
    "    \"\"\"\n",
    "    hit, count = (0., 0.)\n",
    "    \n",
    "    #for user_id in np.sort(ratings_test['user_id'].unique()):\n",
    "    for user_id in np.arange(1, 100):\n",
    "        #print('user_id %s' % user_id)\n",
    "        highest_rate_movie_id = \\\n",
    "            ratings_train[(ratings_train.user_id == user_id) & \\\n",
    "                (ratings_train.rating == np.max(ratings_train[ratings_train.user_id == user_id].rating))][['movie_id']]\n",
    "        \n",
    "        highest_rate_movie_id_list = highest_rate_movie_id.movie_id.values\n",
    "        # Performance will have significant impact if not limit the number of\n",
    "        # rated movies for filtering \n",
    "        random.shuffle(highest_rate_movie_id_list)\n",
    "        highest_rate_movie_id_list = highest_rate_movie_id_list[:rated_movie_limit]\n",
    "        \n",
    "        recommend_list = genre_recommend_by_movid_list(highest_rate_movie_id_list)\n",
    "        #print(user_id, recommend_list)\n",
    "        \n",
    "        for item in recommend_list:\n",
    "            count += 1\n",
    "            x = ratings_test[ratings_test.user_id == user_id][['movie_id', 'rating']]\n",
    "            if x[x.movie_id == item].empty:\n",
    "                continue\n",
    "            elif x[x.movie_id == item].rating.values < np.percentile(x.rating.values, 80):\n",
    "                continue\n",
    "            else:\n",
    "                hit += 1\n",
    "    \n",
    "    print(hit, count)\n",
    "    #hit_ratio = hit / ratings_test.movie_id.count() * 1.0\n",
    "    hit_ratio = hit / count\n",
    "    return hit_ratio\n",
    "        \n",
    "        \n",
    "hit_ratio = hit_ratio_benchmark(ratings_train, ratings_test)\n",
    "hit_ratio *= 100\n",
    "print('hit ratio percentage: %.10f%%' % hit_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG原理见，\n",
    "http://sofasofa.io/forum_main_post.php?postid=1002561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所有验证集的用户的推荐列表，计算ndcg并计算他们的平均值，作为该推荐算法的ndcg分数\n",
    "由于ndcg计算的是推荐列表的顺序的精确度，因此如果验证集中该用户没有给推荐的电影打分，就认为是打了0分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15149997257459272\n"
     ]
    }
   ],
   "source": [
    "def ndcg_benchmark(ratings_train, ratings_test, rated_movie_limit=10):\n",
    "    \"\"\"\n",
    "    for each user_id\n",
    "    1. get recommend list using ratings_train rated movies\n",
    "    2. use ratings_test rated movies to validate ndcg value\n",
    "    if it is not rated, make it zero\n",
    "    return average ndcg_score for all ratings_test users\n",
    "    \"\"\"\n",
    "    \n",
    "    ndcg_score, count = (0, 0)\n",
    "    #for user_id in np.sort(ratings_test['user_id'].unique()):\n",
    "    for user_id in np.arange(1, 100):\n",
    "        r = []\n",
    "        #print('user_id %s' % user_id)\n",
    "        highest_rate_movie_id = \\\n",
    "            ratings_train[(ratings_train.user_id == user_id) & \\\n",
    "                (ratings_train.rating == np.max(ratings_train[ratings_train.user_id == user_id].rating))][['movie_id']]\n",
    "        \n",
    "        highest_rate_movie_id_list = highest_rate_movie_id.movie_id.values\n",
    "        # Performance will have significant impact if not limit the number of\n",
    "        # rated movies for filtering \n",
    "        random.shuffle(highest_rate_movie_id_list)\n",
    "        highest_rate_movie_id_list = highest_rate_movie_id_list[:rated_movie_limit]\n",
    "        \n",
    "        recommend_list = genre_recommend_by_movid_list(highest_rate_movie_id_list)\n",
    "        #print(user_id, recommend_list)\n",
    "        \n",
    "        for item in recommend_list:\n",
    "            x = ratings_test[ratings_test.user_id == user_id][['movie_id', 'rating']]\n",
    "            if x[x.movie_id == item].empty:\n",
    "                r.append(0)\n",
    "            else:\n",
    "                r.append(\\\n",
    "                    np.asscalar(ratings_test[(ratings_test.user_id == user_id) & \\\n",
    "                        (ratings_test.movie_id == item)].rating.values))\n",
    "    \n",
    "        ndcg_score += ndcg_at_k(r, len(r))\n",
    "        count += 1.0\n",
    "\n",
    "    ndcg_score /= count\n",
    "    return ndcg_score\n",
    "\n",
    "print(ndcg_benchmark(ratings_train, ratings_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到hit ratio和NDCG的值都偏低。原因包括该验证集并不是由新的推荐算法的产生的，实际生产中更多会通过A/B方式做验证。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2] *",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
