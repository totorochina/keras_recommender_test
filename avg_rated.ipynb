{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于已打分的电影，算出平均分后，对P90的电影随机推荐高分电影（作对比用途）\n",
    "\n",
    "导入movielen数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reading ratings file\n",
    "# Ignore the timestamp column\n",
    "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Reading users file\n",
    "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据ratings的数据数据，groupby movie id，算出每个movie id的rating的平均值，作为一个dataframe备用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ratings.groupby('movie_id').rating.sum()/ratings.groupby('movie_id').rating.count()\n",
    "movie_avg = pd.DataFrame(a.values, index=a.index, columns=['avg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个函数分别为，\n",
    "一、单纯返回最高评分的若干movie id作为推荐列表。主要问题是所有用户看到的结果是一致的；\n",
    "二、返回最高评分P90的movie id，经过随机处理再推荐。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_high_rated_list(movie_avg_pd, n=10):\n",
    "    \"\"\"\n",
    "    Return movie id list of most high average rated movies\n",
    "    \"\"\"\n",
    "    return movie_avg_pd.sort_values(by=['avg'], inplace=False, ascending=False).head(n).index.values\n",
    "\n",
    "\n",
    "def gen_high_rated_p90_list(movie_avg_pd, n=10):\n",
    "    \"\"\"\n",
    "    Return movie id list of most high average rated movies, >= p90\n",
    "    randomnize to avoid always recommending the same list\n",
    "    \"\"\"\n",
    "    movie_id_list = movie_avg[movie_avg.avg >= movie_avg.avg.quantile(0.9)].index.values\n",
    "    random.shuffle(movie_id_list)\n",
    "    \n",
    "    return movie_id_list[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集以默认1：3的比例以随机的方式分为训练和验证的部分，后续用验证集来验证推荐效果。 具体见， https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train & test data\n",
    "ratings_train, ratings_test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过推荐列表的命中率验证效果，使用验证集来验证推荐结果，训练集用来生成推荐列表。 由于movielen里除了有评价过的电影还有相应的评分，为了贴合实际，认为， 只有命中且评分高于该用户的p80的评分（有些人习惯打高分，其他人反之），才算命中\n",
    "\n",
    "会执行很久，但可以像下列例子那样仅验证头100个user的推荐的命中率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "hit ratio percentage: 0.0000000000%\n"
     ]
    }
   ],
   "source": [
    "def hit_ratio_benchmark(ratings_train, ratings_test, rated_movie_limit=10):\n",
    "    \"\"\"\n",
    "    for each user_id\n",
    "    1. get recommend list using ratings_train rated movies\n",
    "    2. use ratings_test rated movies to validate hit ratio\n",
    "    it is considered hit when,\n",
    "    1. user rated this movie\n",
    "    2. the rate is >= this user's p80 rate in ratings_train\n",
    "    \"\"\"\n",
    "    hit = 0\n",
    "    \n",
    "    #for user_id in np.sort(ratings_test['user_id'].unique()):\n",
    "    for user_id in np.arange(1, 100):\n",
    "        recommend_list = gen_high_rated_p90_list(movie_avg)\n",
    "        #print(\"%s, %s\" % (user_id, recommend_list))\n",
    "        \n",
    "        for item in recommend_list:\n",
    "            x = ratings_test[ratings_test.user_id == user_id][['movie_id', 'rating']]\n",
    "            if x[x.movie_id == item].empty:\n",
    "                continue\n",
    "            elif x[x.movie_id == item].rating.values < np.percentile(x.rating.values, 80):\n",
    "                continue\n",
    "            else:\n",
    "                hit += 1\n",
    "    \n",
    "    print(hit)\n",
    "    hit_ratio = hit / ratings_test.movie_id.count() * 1.0\n",
    "    return hit_ratio\n",
    "        \n",
    "        \n",
    "hit_ratio = hit_ratio_benchmark(ratings_train, ratings_test)\n",
    "hit_ratio *= 100\n",
    "print('hit ratio percentage: %.10f%%' % hit_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG原理见， http://sofasofa.io/forum_main_post.php?postid=1002561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所有验证集的用户的推荐列表，计算ndcg并计算他们的平均值，作为该推荐算法的ndcg分数 由于ndcg计算的是推荐列表的顺序的精确度，因此如果验证集中该用户没有给推荐的电影打分，就认为是打了0分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09268070152565544\n"
     ]
    }
   ],
   "source": [
    "def ndcg_benchmark(ratings_train, ratings_test, rated_movie_limit=10):\n",
    "    \"\"\"\n",
    "    for each user_id\n",
    "    1. get recommend list using ratings_train rated movies\n",
    "    2. use ratings_test rated movies to validate ndcg value\n",
    "    if it is not rated, make it zero\n",
    "    return average ndcg_score for all ratings_test users\n",
    "    \"\"\"\n",
    "    \n",
    "    ndcg_score, count = (0, 0)\n",
    "    #for user_id in np.sort(ratings_test['user_id'].unique()):\n",
    "    for user_id in np.arange(1, 100):\n",
    "        r = []\n",
    "        #print('user_id %s' % user_id)\n",
    "        \n",
    "        recommend_list = gen_high_rated_p90_list(movie_avg)\n",
    "        #print(user_id, recommend_list)\n",
    "        \n",
    "        for item in recommend_list:\n",
    "            x = ratings_test[ratings_test.user_id == user_id][['movie_id', 'rating']]\n",
    "            if x[x.movie_id == item].empty:\n",
    "                r.append(0)\n",
    "            else:\n",
    "                r.append(\\\n",
    "                    np.asscalar(ratings_test[(ratings_test.user_id == user_id) & \\\n",
    "                        (ratings_test.movie_id == item)].rating.values))\n",
    "    \n",
    "        ndcg_score += ndcg_at_k(r, len(r))\n",
    "        count += 1.0\n",
    "\n",
    "    ndcg_score /= count\n",
    "    return ndcg_score\n",
    "\n",
    "print(ndcg_benchmark(ratings_train, ratings_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到hit ratio和NDCG的值都偏低。原因包括该验证集并不是由新的推荐算法的产生的，实际生产中更多会通过A/B方式做验证。\n",
    "同时，推荐最高分p90的结果明显比只推荐最高评分的若干movie id效果要好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2] *",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
